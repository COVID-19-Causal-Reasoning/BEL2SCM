{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import torch\n",
    "import pyro\n",
    "import pandas as pd\n",
    "# import covid19kg\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from pyro.infer import Importance, EmpiricalMarginal\n",
    "from torch.distributions.transforms import AffineTransform\n",
    "import pyro.distributions as dist\n",
    "pyro.set_rng_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self):\n",
    "        self.root = True\n",
    "        self.children = []\n",
    "        self.parent_relations = []\n",
    "        self.child_relations = []\n",
    "        self.name = \"\"\n",
    "        self.node_type = \"\"\n",
    "        self.node_label = \"\"\n",
    "        self.children_type = []\n",
    "        self.children_label = []\n",
    "        self.parents = []\n",
    "        self.parent_type = []\n",
    "        self.parent_label = []\n",
    "        \n",
    "    \n",
    "    def get_node_information(self, sub, obj, rel):\n",
    "        if rel.find('crease') > 0:\n",
    "            self.name = sub\n",
    "            self.children.append(obj)\n",
    "            self.child_relations.append(rel)\n",
    "\n",
    "            p= sub\n",
    "            c= obj\n",
    "            ptype = p[:p.find('(')]\n",
    "            ctype = c[:c.find('(')]\n",
    "\n",
    "            self.node_type = ptype\n",
    "            self.children_type.append(ctype)\n",
    "\n",
    "            for label in label_dict:\n",
    "                if ptype in label_dict[label]:\n",
    "                    self.node_label = label\n",
    "                elif ptype == '': \n",
    "                    self.node_label = 'Others'\n",
    "            for label in label_dict:\n",
    "                if ctype in label_dict[label]:\n",
    "                    self.children_label.append(label)\n",
    "                elif ctype == '': \n",
    "                    self.children_label.append('Others')\n",
    "                    break\n",
    "                    \n",
    "    def update_parent_node(self, obj, rel):\n",
    "        if rel.find('crease') > 0:\n",
    "            self.children.append(obj)\n",
    "            self.child_relations.append(rel)\n",
    "            \n",
    "            c = obj\n",
    "            ctype = c[:c.find('(')]\n",
    "            self.children_type.append(ctype)\n",
    "            for label in label_dict:\n",
    "                if ctype in label_dict[label]:\n",
    "                    self.children_label.append(label)\n",
    "                elif ctype == '': \n",
    "                    self.children_label.append('Others')\n",
    "                    break\n",
    "                    \n",
    "    def update_child_node(self, sub, rel):\n",
    "        self.root = False\n",
    "        if rel.find('crease') > 0:\n",
    "            self.parents.append(sub)\n",
    "            self.parent_relations.append(rel)\n",
    "            p = sub\n",
    "            c = self.name      \n",
    "            ptype = p[:p.find('(')]\n",
    "            ctype = c[:c.find('(')]\n",
    "            self.node_type = ctype\n",
    "            self.parent_type.append(ptype)\n",
    "            for label in label_dict:\n",
    "                if ptype in label_dict[label]:\n",
    "                    self.parent_label.append(label)\n",
    "                elif ptype == '': \n",
    "                    self.parent_label.append('Others')\n",
    "            for label in label_dict:\n",
    "                if ctype in label_dict[label]:\n",
    "                    self.node_label = label\n",
    "                elif ctype == '': \n",
    "                    self.node_label = 'Others'\n",
    "                    break\n",
    "            \n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a generic function to take BEL statements as input\n",
    "## in any form and return a data structure as output \n",
    "## in desired format\n",
    "\n",
    "## Created with the assumptions that inputs are bel statements of some sort\n",
    "\n",
    "\n",
    "label_dict = {'Abundance':['a', 'r', 'm', 'g', 'p','pop', 'composite',\n",
    "                           'complex','frag','fus','loc','pmod','var'],\n",
    "             'Process': ['bp', 'path','act'],\n",
    "             'Transformation':['sec','surf','deg','rxn','tloc','fromLoc',\n",
    "                               'products','reactants','toLoc']}\n",
    "\n",
    "def get_graph(str_list=[],bel_graph=[],jgf_file=[],nanopub_file = []):\n",
    "    if str_list:\n",
    "        ## extracting relevant information from string list format\n",
    "        for item in str_list:\n",
    "            sub_ind = item.find('=')\n",
    "            sub_temp = item[:sub_ind-1]\n",
    "            obj_temp = item[sub_ind+3:] \n",
    "            rel_temp = item[sub_ind:sub_ind+2]\n",
    "            ## keeping only increases/decreases type of edges \n",
    "            if sub_temp in nodes:\n",
    "                nodes[sub_temp].update_parent_node(obj_temp, rel_temp)\n",
    "            else:\n",
    "                sub_node= Node()\n",
    "                sub_node.get_node_information(sub_temp, obj_temp, rel_temp)\n",
    "                nodes[sub_temp] = sub_node\n",
    "                \n",
    "            if obj_temp in nodes:\n",
    "                nodes[obj_temp].update_child_node(sub_temp, rel_temp)\n",
    "            else:\n",
    "                obj_node = Node()\n",
    "                obj_node.name = obj_temp\n",
    "                obj_node.update_child_node(sub_temp, rel_temp)\n",
    "                nodes[obj_temp] = obj_node\n",
    "\n",
    "\n",
    "    elif bel_graph:\n",
    "        ## extracting relevant information from pybel format\n",
    "        for item in bel_graph.edges:\n",
    "            edge_temp = bel_graph.get_edge_data(item[0],item[1],item[2])\n",
    "            sub_temp = str(item[0]).replace('\"','')\n",
    "            obj_temp = str(item[1]).replace('\"','')\n",
    "            rel_temp = edge_temp['relation']\n",
    "\n",
    "            if sub_temp in nodes:\n",
    "                nodes[sub_temp].update_parent_node(obj_temp, rel_temp)\n",
    "            else:\n",
    "                sub_node= Node()\n",
    "                sub_node.get_node_information(sub_temp, obj_temp, rel_temp)\n",
    "                nodes[sub_temp] = sub_node\n",
    "                \n",
    "            if obj_temp in nodes:\n",
    "                nodes[obj_temp].update_child_node(sub_temp, rel_temp)\n",
    "            else:\n",
    "                obj_node = Node()\n",
    "                obj_node.name = obj_temp\n",
    "                obj_node.update_child_node(sub_temp, rel_temp)\n",
    "                nodes[obj_temp] = obj_node\n",
    "\n",
    "\n",
    "    elif jgf_file:\n",
    "        file1 = open(jgf_file)\n",
    "        loaded_jgf = json.load(file1)\n",
    "\n",
    "        for item in loaded_jgf['graph']['edges']:\n",
    "            sub_temp = item['source']\n",
    "            obj_temp = item['target']\n",
    "            rel_temp = item['relation']\n",
    "            if sub_temp in nodes:\n",
    "                nodes[sub_temp].update_parent_node(obj_temp, rel_temp)\n",
    "            else:\n",
    "                sub_node= Node()\n",
    "                sub_node.get_node_information(sub_temp, obj_temp, rel_temp)\n",
    "                nodes[sub_temp] = sub_node\n",
    "                \n",
    "            if obj_temp in nodes:\n",
    "                nodes[obj_temp].update_child_node(sub_temp, rel_temp)\n",
    "            else:\n",
    "                obj_node = Node()\n",
    "                obj_node.name = obj_temp\n",
    "                obj_node.update_child_node(sub_temp, rel_temp)\n",
    "                nodes[obj_temp] = obj_node\n",
    "\n",
    "    elif nanopub_file:\n",
    "        file1 = open(nanopub_file)\n",
    "        loaded_nanopub = json.load(file1)\n",
    "        for item in loaded_nanopub[0]['nanopub']['assertions']:\n",
    "            sub_temp = item['subject']\n",
    "            obj_temp = item['object']\n",
    "            rel_temp = item['relation']\n",
    "            if sub_temp in nodes:\n",
    "                nodes[sub_temp].update_parent_node(obj_temp, rel_temp)\n",
    "            else:\n",
    "                sub_node= Node()\n",
    "                sub_node.get_node_information(sub_temp, obj_temp, rel_temp)\n",
    "                nodes[sub_temp] = sub_node\n",
    "                \n",
    "            if obj_temp in nodes:\n",
    "                nodes[obj_temp].update_child_node(sub_temp, rel_temp)\n",
    "            else:\n",
    "                obj_node = Node()\n",
    "                obj_node.name = obj_temp\n",
    "                obj_node.update_child_node(sub_temp, rel_temp)\n",
    "                nodes[obj_temp] = obj_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('config.json')\n",
    "config = json.load(f)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_graph(nanopub_file='COVID-19-new.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for keys in nodes:\n",
    "#     print(keys)\n",
    "#     print(\"name\", nodes[keys].name)\n",
    "#     print(\"root\", nodes[keys].root)\n",
    "#     print(\"children\", nodes[keys].children)\n",
    "#     print(\"child relation\", nodes[keys].child_relations)\n",
    "#     print(\"child label\", nodes[keys].children_label)\n",
    "#     print(\"node type\", nodes[keys].node_type)\n",
    "#     print(\"node label\", nodes[keys].node_label)\n",
    "#     print(\"parents\", nodes[keys].parents)\n",
    "#     print(\"parent relation\", nodes[keys].parent_relations)\n",
    "#     print(\"parent label\",nodes[keys].parent_label )\n",
    "#     print()\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution(node_dist: str, dist_parameters: list) -> dist:\n",
    "    \"\"\"\n",
    "    Description: This function is to get the distribution for a node based on its type\n",
    "    Parameters: the node's type\n",
    "    Returns: sampled values for node in tensor format based on its type\n",
    "    \"\"\"\n",
    "\n",
    "    if node_dist == 'Lognormal':\n",
    "        return dist.LogNormal(torch.tensor(dist_parameters[0]), torch.tensor(dist_parameters[1]))\n",
    "    if node_dist == 'Process':\n",
    "        return dist.Categorical(torch.tensor(dist_parameters))\n",
    "    if node_dist == \"Gamma\":\n",
    "        return dist.Gamma(torch.tensor(dist_parameters[0]), torch.tensor(dist_parameters[1]))\n",
    "    if node_dist == \"Normal\":\n",
    "        return dist.Normal(torch.tensor(dist_parameters[0]), torch.tensor(dist_parameters[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_increase(x, threshold):\n",
    "    \"\"\"\n",
    "    Description: Helper function for SCM_model(), \n",
    "                 to be used with increasing type edges\n",
    "    Parameters:  Result of parents' equation (x)\n",
    "    Returns:     1.0 if value is greater than set threshold\n",
    "                 else 0.0\n",
    "    \"\"\"\n",
    "    # threshold = 0.5\n",
    "    if x > threshold:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def check_decrease(x, threshold):\n",
    "    \"\"\"\n",
    "    Description: Helper function for SCM_model(), \n",
    "                 to be used with decreasing type edges\n",
    "    Parameters:  Result of parents' equation (x)\n",
    "    Returns:     0.0 if value is greater than set threshold\n",
    "                 else 1.0\n",
    "    \"\"\"\n",
    "    # threshold = 0.5\n",
    "    if x > threshold:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_sample(parent_name, child_name, child_label, parent_label, parents, relation, w, threshold, normal, noise, \\\n",
    "#               increaseProcess, decreaseProcess):\n",
    "#     child_increase_N = 0 \n",
    "#     child_decrease_N = 0\n",
    "#     for i in range(len(parent_label)):\n",
    "#         if relation[i] == 'increases' or relation[i] == 'directlyIncreases':\n",
    "#             if parent_label[i] == 'Abundance':\n",
    "#                 child_increase_N += w[i] * parents[i]\n",
    "#             if parent_label[i] == 'Transformation':\n",
    "#                 child_increase_N += w[i] *(parents[i] * parents[i])\n",
    "            \n",
    "#         else:\n",
    "#             if parent_label[i] == 'Abundance':\n",
    "#                 child_decrease_N += w[i] * parents[i]\n",
    "#             if parent_label[i] == 'Transformation':\n",
    "#                 child_decrease_N += w[i] * parents[i] * parents[i]\n",
    "\n",
    "    \n",
    "#     if child_label == 'Process':\n",
    "#         child_name_noise = child_name + \"_N\"\n",
    "#         child_noise = pyro.sample(child_name_noise, normal)\n",
    "#         child_check = check_increase(child_increase_N + child_noise + sum(increaseProcess), (len(parent_label))*threshold) + \\\n",
    "#                       check_decrease(child_decrease_N + child_noise + sum(decreaseProcess), (len(parent_label))*threshold)\n",
    "#         if len(increaseProcess) == 0 and len(decreaseProcess) > 0 and child_check == 1.0:\n",
    "#             child_N = torch.tensor(1.0)\n",
    "#         elif len(decreaseProcess) == 0 and len(increaseProcess) > 0 and child_check == 1.0:\n",
    "#             child_N = torch.tensor(1.0)\n",
    "#         elif child_check == 2.0:\n",
    "#             child_N = torch.tensor(1.0)\n",
    "#         else:\n",
    "#             child_N = torch.tensor(0.)\n",
    "\n",
    "#     elif child_label == 'Abundance':\n",
    "#         child_name_noise = child_name + \"_N\"\n",
    "        \n",
    "#         child_noise = pyro.sample(child_name_noise, dist.LogNormal(torch.tensor(mu_a),torch.tensor(sigma_a)))\n",
    "#         child_N = child_increase_N - child_decrease_N + child_noise\n",
    "#     else:\n",
    "#         child_name_noise = child_name + \"_N\"\n",
    "#         child_noise = pyro.sample(child_name_noise, noise)\n",
    "#         #child_noise = pyro.sample(child_name_noise, dist.LogNormal(torch.tensor(mu_a),torch.tensor(sigma_a)))\n",
    "#         child_N = child_increase_N - child_decrease_N + child_noise\n",
    "        \n",
    "#     return child_N\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abundance_sample(weights_a: list, p_sample_a: list):\n",
    "    return sum(x * y for x, y in zip(weights_a, p_sample_a))\n",
    "\n",
    "\n",
    "def get_transformation_sample(weights_t: list, p_sample_t: list):\n",
    "    return sum(x * y * y for x, y in zip(weights_t, p_sample_t))\n",
    "\n",
    "\n",
    "def get_sample(child_name: str,\n",
    "               child_label: str,\n",
    "               parent_label: list,\n",
    "               threshold: float,\n",
    "               normal: dist,\n",
    "               noise: dist,\n",
    "               increase_process: list,\n",
    "               decrease_process: list, \n",
    "               increase_abundance: list,\n",
    "              decrease_abundance: list,\n",
    "               weights_ai: list,\n",
    "               weights_ad: list,\n",
    "              increase_transformation, \n",
    "              decrease_transformation, \n",
    "              weights_ti: list,\n",
    "              weights_td: list) -> float:\n",
    "    \n",
    "    child_increase_N = 0\n",
    "    child_decrease_N = 0\n",
    "    \n",
    "    child_increase_N = get_abundance_sample(weights_ai, increase_abundance) + \\ \n",
    "    get_transformation_sample(weights_ti, increase_transformation)\n",
    "    \n",
    "    child_decrease_N = get_abundance_sample(weights_ad, decrease_abundance) + \\ \n",
    "    get_transformation_sample(weights_td, decrease_transformation)\n",
    "    \n",
    "    if child_label == 'transformation':\n",
    "        child_name_noise = child_name + \"_N\"\n",
    "        child_noise = pyro.sample(child_name_noise, noise)\n",
    "        child_N = child_increase_N - child_decrease_N + child_noise\n",
    "\n",
    "    elif child_label == 'Abundance':\n",
    "        child_name_noise = child_name + \"_N\"\n",
    "        child_noise = pyro.sample(child_name_noise, dist.LogNormal(torch.tensor(mu_a), torch.tensor(sigma_a)))\n",
    "        child_N = child_increase_N - child_decrease_N + child_noise\n",
    "        \n",
    "    else:\n",
    "        child_name_noise = child_name + \"_N\"\n",
    "        child_noise = pyro.sample(child_name_noise, normal)\n",
    "        child_check = check_increase(child_increase_N + child_noise + sum(increaseProcess),\n",
    "                                     (len(parent_label)) * threshold) + \\\n",
    "                      check_decrease(child_decrease_N + child_noise + sum(decreaseProcess),\n",
    "                                     (len(parent_label)) * threshold)\n",
    "        if len(increaseProcess) == 0 and len(decreaseProcess) > 0 and child_check == 1.0:\n",
    "            child_N = torch.tensor(1.0)\n",
    "        elif len(decreaseProcess) == 0 and len(increaseProcess) > 0 and child_check == 1.0:\n",
    "            child_N = torch.tensor(1.0)\n",
    "        elif child_check == 2.0:\n",
    "            child_N = torch.tensor(1.0)\n",
    "        else:\n",
    "            child_N = torch.tensor(0.)\n",
    "\n",
    "    return child_N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCM(nodes, config):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description: This function is to be build a Structural Causal Model for \n",
    "                  for any child-parent cluster\n",
    "    Parameters: knowledge graph as dataframe, \n",
    "                threshold for cutoff \n",
    "                weights for each parents\n",
    "    Returns: sampled values for all nodes in tensor format\n",
    "    \"\"\"\n",
    "    pyro_settings = config[\"pyro_settings\"]\n",
    "    node_settings = config[\"node_type_settings\"]\n",
    "    exogenous_var_settings = config[\"exogenous_var_settings\"]\n",
    "    threshold = pyro_settings[\"threshold\"]\n",
    "    weight = pyro_settings[\"weights\"]\n",
    "    samples = {}\n",
    "    exogenous = []\n",
    "    current_node = None\n",
    "    root_list = []\n",
    "    node_list = []\n",
    "    visited = []\n",
    "\n",
    "    for node in nodes:\n",
    "        if nodes[node].root == True:\n",
    "            root_list.append(node)\n",
    "    for node in root_list:\n",
    "        parent = pyro.sample(node, get_distribution(nodes[node].node_label,mu_a,\n",
    "                                                                sigma_a,\n",
    "                                                                mu_t,\n",
    "                                                                sigma_t,\n",
    "                                                                cat_1,\n",
    "                                                                cat_0))\n",
    "        samples[node] = parent\n",
    "        visited.append(node)\n",
    "        c_list = nodes[node].children\n",
    "        for c in c_list:\n",
    "            node_list.append(c)\n",
    "        \n",
    "            \n",
    "    while len(node_list) > 0:\n",
    "        current_node = node_list[0]\n",
    "        parent_label = nodes[current_node].parent_label\n",
    "        child_label = nodes[current_node].node_label\n",
    "        relation = nodes[current_node].parent_relations\n",
    "        parent_name = nodes[current_node].parents\n",
    "        child_name = nodes[current_node].name\n",
    "        w = [weight]*len(parent_label)\n",
    "        \n",
    "        parents = []\n",
    "        increaseProcess = []\n",
    "        decreaseProcess = []\n",
    "        noise = dist.Gamma(torch.tensor(alpha),torch.tensor(beta))\n",
    "        normal = dist.Normal(torch.tensor(0.0),torch.tensor(0.1))\n",
    "        visited_parents_count = 0\n",
    "        \n",
    "        \n",
    "        for i in range(len(parent_label)):\n",
    "            if parent_name[i] in samples:\n",
    "                parents.append(samples[parent_name[i]])\n",
    "                visited_parents_count += 1\n",
    "\n",
    "                if relation[i] == 'decreases' or relation[i] == 'directlyDecreases':\n",
    "                    if parent_label[i] == 'Process':\n",
    "                        decreaseProcess.append(samples[parent_name[i]])\n",
    "                else:\n",
    "                    if parent_label[i] == 'Process':\n",
    "                        increaseProcess.append(samples[parent_name[i]])\n",
    "        if visited_parents_count != len(parent_label):\n",
    "            node_list.pop(0)\n",
    "            continue\n",
    "        if child_name not in visited:\n",
    "            if \"Process\" in parent_label:\n",
    "                if sum(decreaseProcess) == 0 and sum(increaseProcess) == len(increaseProcess):\n",
    "                    child_N = get_sample(parent_name, child_name, child_label, parent_label, parents, relation, w, threshold, normal, noise, increaseProcess, decreaseProcess)\n",
    "                else:\n",
    "                    child_N = torch.tensor(0.)\n",
    "            else:\n",
    "                child_N = get_sample(parent_name, child_name, child_label, parent_label, parents, relation, w, threshold, normal, noise, increaseProcess, decreaseProcess)\n",
    "                \n",
    "            child = pyro.sample(child_name, pyro.distributions.Delta(child_N))\n",
    "            samples[child_name] = child\n",
    "            visited.append(child_name)\n",
    "        \n",
    "        c_list = nodes[current_node].children\n",
    "        for c in c_list:\n",
    "            node_list.append(c)\n",
    "        node_list.pop(0)\n",
    "\n",
    "                           \n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(SCM())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intervention(model, do_variable, do_val, target_variable):\n",
    "    \"\"\"\n",
    "      Description: This is a function to perform intervention\n",
    "      query for sampling\n",
    "      Parameters:  Structural Causal Model (model),\n",
    "               a list of variables to be intervened (do_variable),\n",
    "               list of values for intervened variables in\n",
    "               same order (do_val),\n",
    "               target variable (target_variable)\n",
    "      Returns:  probability of target variable in given setting\n",
    "    \"\"\"\n",
    "    # get the conditions for the do model\n",
    "    conditions = {}\n",
    "    for i in range(len(do_variable)):\n",
    "        conditions[do_variable[i]] = torch.tensor(do_val[i])\n",
    "    do_model = pyro.do(model, data=conditions)\n",
    "    posterior = pyro.infer.Importance(do_model, num_samples=1000).run()\n",
    "    marginal = EmpiricalMarginal(posterior, target_variable)\n",
    "    target = [marginal().item() for i in range(1000)]\n",
    "    return np.mean(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervention(SCM,['bp(GO:\"pattern recognition receptor signaling pathway\")'],[1.],'path(MESH:\"Severe Acute Respiratory Syndrome\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervention(SCM,['act(p(HGNC:ACE2))'],[0.0],'path(MESH:\"Severe Acute Respiratory Syndrome\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
